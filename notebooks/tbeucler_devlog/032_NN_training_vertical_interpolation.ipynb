{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tgb - 11/27/2019 - Training the network for data that was vertically-interpolated on the eps grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1205 09:15:24.451553 22712538859328 deprecation_wrapper.py:119] From /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1205 09:15:24.452144 22712538859328 deprecation_wrapper.py:119] From /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 09:15:24.734439 22712538859328 deprecation_wrapper.py:119] From /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/cbrain/utils.py:145: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1205 09:15:24.734985 22712538859328 deprecation_wrapper.py:119] From /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/cbrain/utils.py:148: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "W1205 09:15:24.735433 22712538859328 deprecation_wrapper.py:119] From /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/cbrain/utils.py:148: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n"
     ]
    }
   ],
   "source": [
    "from cbrain.imports import *\n",
    "from cbrain.data_generator import *\n",
    "from cbrain.cam_constants import *\n",
    "from cbrain.losses import *\n",
    "from cbrain.utils import limit_mem\n",
    "from cbrain.layers import *\n",
    "from cbrain.data_generator import DataGenerator\n",
    "import tensorflow as tf\n",
    "import tensorflow.math as tfm\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from cbrain.model_diagnostics import ModelDiagnostics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imag\n",
    "import scipy.integrate as sin\n",
    "\n",
    "TRAINDIR = '/local/Tom.Beucler/SPCAM_PHYS/'\n",
    "DATADIR = '/project/meteo/w2w/A6/S.Rasp/SP-CAM/fluxbypass_aqua/'\n",
    "PREFIX = '8col009_01_'\n",
    "%cd /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
    "\n",
    "# Otherwise tensorflow will use ALL your GPU RAM for no reason\n",
    "limit_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Design NN with RH_eps and T_eps as inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = {\n",
    "    'PHQEPS': L_V/G,  \n",
    "    'TPHYSTNDEPS': C_P/G, \n",
    "    'FSNT': 1, \n",
    "    'FSNS': 1, \n",
    "    'FLNT': 1, \n",
    "    'FLNS': 1, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quick test, use equal pressure thickness for all eps layers (equal weighting in eps space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS = 1e5\n",
    "eps_res = 1e2\n",
    "dP = PS/eps_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['PHQEPS','TPHYSTNDEPS']:\n",
    "    scale_dict[v] *= dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle('./nn_config/scale_dicts/127_POG_scaling.pkl', scale_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Build data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RHEPS','TBPEPS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQEPS','TPHYSTNDEPS','FSNT','FSNS','FLNT','FLNS']\n",
    "train_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/131_train_shuffle.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/131_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/131_valid.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/131_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 204), (1024, 204))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = valid_gen[12]; X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce number of layers to 5 since less data and wider layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1128 07:43:50.146628 23269534324544 deprecation.py:506] From /home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(204,))\n",
    "densout = Dense(256, activation='linear')(inp)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "for i in range (3):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dense(204, activation='linear')(densout)\n",
    "out = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel = tf.keras.models.Model(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 204)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               52480     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 204)               52428     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 204)               0         \n",
      "=================================================================\n",
      "Total params: 302,284\n",
      "Trainable params: 302,284\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG131.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3448/3448 [==============================] - 44s 13ms/step - loss: 31.9895 - val_loss: 32.5142\n",
      "Epoch 2/20\n",
      "3448/3448 [==============================] - 43s 12ms/step - loss: 31.6992 - val_loss: 32.5529\n",
      "Epoch 3/20\n",
      "3448/3448 [==============================] - 43s 13ms/step - loss: 31.4743 - val_loss: 31.9120\n",
      "Epoch 4/20\n",
      "3448/3448 [==============================] - 45s 13ms/step - loss: 31.2693 - val_loss: 31.7280\n",
      "Epoch 5/20\n",
      "3448/3448 [==============================] - 45s 13ms/step - loss: 31.1017 - val_loss: 31.7779\n",
      "Epoch 6/20\n",
      "3448/3448 [==============================] - 47s 14ms/step - loss: 30.9046 - val_loss: 31.7368\n",
      "Epoch 7/20\n",
      "3448/3448 [==============================] - 45s 13ms/step - loss: 30.7238 - val_loss: 31.3456\n",
      "Epoch 8/20\n",
      "3448/3448 [==============================] - 45s 13ms/step - loss: 30.5716 - val_loss: 32.7376\n",
      "Epoch 9/20\n",
      "3448/3448 [==============================] - 48s 14ms/step - loss: 30.4611 - val_loss: 31.3613\n",
      "Epoch 10/20\n",
      "3448/3448 [==============================] - 60s 17ms/step - loss: 30.3145 - val_loss: 31.5924\n",
      "Epoch 11/20\n",
      "3448/3448 [==============================] - 48s 14ms/step - loss: 30.1781 - val_loss: 31.2466\n",
      "Epoch 12/20\n",
      "3448/3448 [==============================] - 45s 13ms/step - loss: 30.1086 - val_loss: 32.0075\n",
      "Epoch 13/20\n",
      "3448/3448 [==============================] - 56s 16ms/step - loss: 29.9334 - val_loss: 32.0300\n",
      "Epoch 14/20\n",
      "3448/3448 [==============================] - 66s 19ms/step - loss: 29.8530 - val_loss: 31.3336\n",
      "Epoch 15/20\n",
      "3448/3448 [==============================] - 58s 17ms/step - loss: 29.7568 - val_loss: 31.4402\n",
      "Epoch 16/20\n",
      "3448/3448 [==============================] - 60s 17ms/step - loss: 29.6575 - val_loss: 31.3121\n",
      "Epoch 17/20\n",
      "3448/3448 [==============================] - 52s 15ms/step - loss: 29.5554 - val_loss: 31.2283\n",
      "Epoch 18/20\n",
      "3448/3448 [==============================] - 52s 15ms/step - loss: 29.4805 - val_loss: 31.1828\n",
      "Epoch 19/20\n",
      "3448/3448 [==============================] - 53s 15ms/step - loss: 29.3757 - val_loss: 31.0474\n",
      "Epoch 20/20\n",
      "3448/3448 [==============================] - 53s 15ms/step - loss: 29.2830 - val_loss: 31.5480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1529412d0c88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Repeat with larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RHEPS','TBPEPS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQEPS','TPHYSTNDEPS','FSNT','FSNS','FLNT','FLNS']\n",
    "train_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/132_train_shuffle.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/131_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/132_valid.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/131_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 204), (1024, 204))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = valid_gen[19]; X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1128 20:34:22.045083 22889390782272 deprecation.py:506] From /home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "inp2 = Input(shape=(204,))\n",
    "densout = Dense(256, activation='linear')(inp2)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "for i in range (5):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dense(204, activation='linear')(densout)\n",
    "out2 = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel2 = tf.keras.models.Model(inp2,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 204)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               52480     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 204)               52428     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 204)               0         \n",
      "=================================================================\n",
      "Total params: 433,868\n",
      "Trainable params: 433,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG132.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel2.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18336/18336 [==============================] - 324s 18ms/step - loss: 41.6340 - val_loss: 35.3406\n",
      "Epoch 2/20\n",
      "18336/18336 [==============================] - 234s 13ms/step - loss: 32.7102 - val_loss: 33.4377\n",
      "Epoch 3/20\n",
      "18336/18336 [==============================] - 235s 13ms/step - loss: 31.3168 - val_loss: 32.3228\n",
      "Epoch 4/20\n",
      "18336/18336 [==============================] - 240s 13ms/step - loss: 30.5962 - val_loss: 30.9279\n",
      "Epoch 5/20\n",
      "18336/18336 [==============================] - 239s 13ms/step - loss: 30.1226 - val_loss: 30.9347\n",
      "Epoch 6/20\n",
      "18336/18336 [==============================] - 235s 13ms/step - loss: 29.7778 - val_loss: 30.4701\n",
      "Epoch 7/20\n",
      "18336/18336 [==============================] - 237s 13ms/step - loss: 29.4979 - val_loss: 30.9430\n",
      "Epoch 8/20\n",
      "18336/18336 [==============================] - 237s 13ms/step - loss: 29.2758 - val_loss: 29.9549\n",
      "Epoch 9/20\n",
      "18336/18336 [==============================] - 237s 13ms/step - loss: 29.0793 - val_loss: 30.0082\n",
      "Epoch 10/20\n",
      "18336/18336 [==============================] - 237s 13ms/step - loss: 28.9086 - val_loss: 29.8657\n",
      "Epoch 11/20\n",
      "18336/18336 [==============================] - 234s 13ms/step - loss: 28.7680 - val_loss: 29.5410\n",
      "Epoch 12/20\n",
      "18336/18336 [==============================] - 236s 13ms/step - loss: 28.6426 - val_loss: 29.7029\n",
      "Epoch 13/20\n",
      "18336/18336 [==============================] - 236s 13ms/step - loss: 28.5254 - val_loss: 29.7696\n",
      "Epoch 14/20\n",
      "18336/18336 [==============================] - 242s 13ms/step - loss: 28.4328 - val_loss: 29.9220\n",
      "Epoch 15/20\n",
      "18336/18336 [==============================] - 242s 13ms/step - loss: 28.3276 - val_loss: 29.3601\n",
      "Epoch 16/20\n",
      "18336/18336 [==============================] - 235s 13ms/step - loss: 28.2393 - val_loss: 29.5475\n",
      "Epoch 17/20\n",
      "18336/18336 [==============================] - 235s 13ms/step - loss: 28.1596 - val_loss: 29.6606\n",
      "Epoch 18/20\n",
      "18336/18336 [==============================] - 235s 13ms/step - loss: 28.0933 - val_loss: 29.3747\n",
      "Epoch 19/20\n",
      "18336/18336 [==============================] - 234s 13ms/step - loss: 28.0131 - val_loss: 29.5025\n",
      "Epoch 20/20\n",
      "18336/18336 [==============================] - 268s 15ms/step - loss: 27.9583 - val_loss: 29.5986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d0b2442048>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel2.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Repeat with only 30 levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/134_POG_RHTepsinput_dQdtdTdtepsotuput_test30lev_June.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = {\n",
    "    'PHQEPS': L_V/G,  \n",
    "    'TPHYSTNDEPS': C_P/G, \n",
    "    'FSNT': 1, \n",
    "    'FSNS': 1, \n",
    "    'FLNT': 1, \n",
    "    'FLNS': 1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS = 1e5\n",
    "eps_res = 30\n",
    "dP = PS/eps_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['PHQEPS','TPHYSTNDEPS']:\n",
    "    scale_dict[v] *= dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle('./nn_config/scale_dicts/134_POG_scaling.pkl', scale_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RHEPS','TBPEPS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQEPS','TPHYSTNDEPS','FSNT','FSNS','FLNT','FLNS']\n",
    "train_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/134_train_shuffle.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/134_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/134_valid.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/134_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 64), (1024, 64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = valid_gen[19]; X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1130 20:55:00.279494 22966316377920 deprecation.py:506] From /home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "for i in range (3):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "out = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel = tf.keras.models.Model(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 230,464\n",
      "Trainable params: 230,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG134.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 293.5796 - val_loss: 295.9517\n",
      "Epoch 2/20\n",
      "3448/3448 [==============================] - 24s 7ms/step - loss: 292.7631 - val_loss: 299.7634\n",
      "Epoch 3/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 292.2214 - val_loss: 292.8768\n",
      "Epoch 4/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 291.7000 - val_loss: 292.6278\n",
      "Epoch 5/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 291.1524 - val_loss: 291.6248\n",
      "Epoch 6/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 290.5519 - val_loss: 295.2890\n",
      "Epoch 7/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 289.9311 - val_loss: 295.7925\n",
      "Epoch 8/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 289.6223 - val_loss: 293.3192\n",
      "Epoch 9/20\n",
      "3448/3448 [==============================] - 25s 7ms/step - loss: 288.9978 - val_loss: 292.0082\n",
      "Epoch 10/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 288.5617 - val_loss: 293.9081\n",
      "Epoch 11/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 288.3005 - val_loss: 291.0258\n",
      "Epoch 12/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 287.7814 - val_loss: 290.8198\n",
      "Epoch 13/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 287.2141 - val_loss: 291.3420\n",
      "Epoch 14/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 286.9507 - val_loss: 290.6447\n",
      "Epoch 15/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 286.4949 - val_loss: 295.0719\n",
      "Epoch 16/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 286.0871 - val_loss: 291.4113\n",
      "Epoch 17/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 285.7590 - val_loss: 290.3744\n",
      "Epoch 18/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 285.4205 - val_loss: 288.9548\n",
      "Epoch 19/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 285.1739 - val_loss: 294.3019\n",
      "Epoch 20/20\n",
      "3448/3448 [==============================] - 22s 6ms/step - loss: 284.8641 - val_loss: 289.1647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e2a09e95f8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Repeat with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp2)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "for i in range (3):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "    densout = Dropout(rate=0.01)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "out2 = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel2 = tf.keras.models.Model(inp2,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 230,464\n",
      "Trainable params: 230,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG134_Dropout.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3448/3448 [==============================] - 39s 11ms/step - loss: 465.9679 - val_loss: 350.4284\n",
      "Epoch 2/20\n",
      "3448/3448 [==============================] - 41s 12ms/step - loss: 352.5980 - val_loss: 332.3417\n",
      "Epoch 3/20\n",
      "3448/3448 [==============================] - 38s 11ms/step - loss: 337.8967 - val_loss: 320.9518\n",
      "Epoch 4/20\n",
      "3448/3448 [==============================] - 42s 12ms/step - loss: 328.3691 - val_loss: 314.6974\n",
      "Epoch 5/20\n",
      "3448/3448 [==============================] - 40s 11ms/step - loss: 322.3559 - val_loss: 310.3371\n",
      "Epoch 6/20\n",
      "3448/3448 [==============================] - 40s 12ms/step - loss: 317.7420 - val_loss: 310.4449\n",
      "Epoch 7/20\n",
      "3448/3448 [==============================] - 42s 12ms/step - loss: 314.4533 - val_loss: 306.2188\n",
      "Epoch 8/20\n",
      "3448/3448 [==============================] - 38s 11ms/step - loss: 311.7743 - val_loss: 304.1707\n",
      "Epoch 9/20\n",
      "3448/3448 [==============================] - 41s 12ms/step - loss: 309.3662 - val_loss: 302.4541\n",
      "Epoch 10/20\n",
      "3448/3448 [==============================] - 39s 11ms/step - loss: 307.5027 - val_loss: 300.1979\n",
      "Epoch 11/20\n",
      "3448/3448 [==============================] - 37s 11ms/step - loss: 305.7026 - val_loss: 298.8847\n",
      "Epoch 12/20\n",
      "3448/3448 [==============================] - 40s 12ms/step - loss: 304.2955 - val_loss: 297.8207\n",
      "Epoch 13/20\n",
      "3448/3448 [==============================] - 37s 11ms/step - loss: 302.9897 - val_loss: 299.3100\n",
      "Epoch 14/20\n",
      "3448/3448 [==============================] - 41s 12ms/step - loss: 301.6807 - val_loss: 295.9187\n",
      "Epoch 15/20\n",
      "3448/3448 [==============================] - 42s 12ms/step - loss: 300.6132 - val_loss: 295.8025\n",
      "Epoch 16/20\n",
      "3448/3448 [==============================] - 44s 13ms/step - loss: 299.8076 - val_loss: 298.1155\n",
      "Epoch 17/20\n",
      "3448/3448 [==============================] - 43s 12ms/step - loss: 298.7390 - val_loss: 293.7615\n",
      "Epoch 18/20\n",
      "3448/3448 [==============================] - 44s 13ms/step - loss: 297.9466 - val_loss: 293.0810\n",
      "Epoch 19/20\n",
      "3448/3448 [==============================] - 42s 12ms/step - loss: 297.0330 - val_loss: 292.7888\n",
      "Epoch 20/20\n",
      "3448/3448 [==============================] - 41s 12ms/step - loss: 296.4752 - val_loss: 292.3502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e2616266d8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Before increasing dataset for eps 30lev, try small dataset for p 30lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = load_pickle('./nn_config/scale_dicts/100_POG_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RH','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQ','TPHYSTND','FSNT','FSNS','FLNT','FLNS']\n",
    "train_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/103_train_shuffle.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/103_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/103_valid.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/103_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 64), (1024, 64))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = valid_gen[19]; X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp5 = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp5)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "for i in range (3):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "out5 = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel5 = tf.keras.models.Model(inp5,out5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 230,464\n",
      "Trainable params: 230,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG104_Small.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel5.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3448/3448 [==============================] - 33s 9ms/step - loss: 783.4452 - val_loss: 646.2542\n",
      "Epoch 2/20\n",
      "3448/3448 [==============================] - 28s 8ms/step - loss: 626.3573 - val_loss: 615.3320\n",
      "Epoch 3/20\n",
      "3448/3448 [==============================] - 39s 11ms/step - loss: 603.5838 - val_loss: 599.2223\n",
      "Epoch 4/20\n",
      "3448/3448 [==============================] - 27s 8ms/step - loss: 588.1144 - val_loss: 586.5352\n",
      "Epoch 5/20\n",
      "3448/3448 [==============================] - 24s 7ms/step - loss: 577.7999 - val_loss: 585.0277\n",
      "Epoch 6/20\n",
      "3448/3448 [==============================] - 24s 7ms/step - loss: 569.8410 - val_loss: 577.7494\n",
      "Epoch 7/20\n",
      "3448/3448 [==============================] - 24s 7ms/step - loss: 563.2021 - val_loss: 572.8820\n",
      "Epoch 8/20\n",
      "3448/3448 [==============================] - 31s 9ms/step - loss: 558.2204 - val_loss: 568.6889\n",
      "Epoch 9/20\n",
      "3448/3448 [==============================] - 39s 11ms/step - loss: 554.1868 - val_loss: 569.0652\n",
      "Epoch 10/20\n",
      "3448/3448 [==============================] - 24s 7ms/step - loss: 550.3422 - val_loss: 558.1307\n",
      "Epoch 11/20\n",
      "3448/3448 [==============================] - 24s 7ms/step - loss: 546.6344 - val_loss: 553.7147\n",
      "Epoch 12/20\n",
      "3448/3448 [==============================] - 25s 7ms/step - loss: 543.6829 - val_loss: 551.7068\n",
      "Epoch 13/20\n",
      "3448/3448 [==============================] - 24s 7ms/step - loss: 540.8559 - val_loss: 551.5332\n",
      "Epoch 14/20\n",
      "3448/3448 [==============================] - 24s 7ms/step - loss: 538.2831 - val_loss: 550.9058\n",
      "Epoch 15/20\n",
      "3448/3448 [==============================] - 24s 7ms/step - loss: 536.2112 - val_loss: 548.2763\n",
      "Epoch 16/20\n",
      "3448/3448 [==============================] - 24s 7ms/step - loss: 533.9947 - val_loss: 548.0641\n",
      "Epoch 17/20\n",
      "3448/3448 [==============================] - 23s 7ms/step - loss: 532.1299 - val_loss: 553.4951\n",
      "Epoch 18/20\n",
      "3448/3448 [==============================] - 29s 8ms/step - loss: 530.2758 - val_loss: 546.5300\n",
      "Epoch 19/20\n",
      "3448/3448 [==============================] - 39s 11ms/step - loss: 528.4397 - val_loss: 539.5005\n",
      "Epoch 20/20\n",
      "3448/3448 [==============================] - 27s 8ms/step - loss: 526.7847 - val_loss: 539.8947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e260ff5828>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel5.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Train eps 30lev with increased dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1) Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1201 10:44:26.517730 22976311719744 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1201 10:44:26.518000 22976311719744 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RHEPS\n",
      "Base variable is  RH\n",
      "var is  TBPEPS\n",
      "Base variable is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQEPS\n",
      "Base variable is  PHQ\n",
      "var is  TPHYSTNDEPS\n",
      "Base variable is  TPHYSTND\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n",
      "100%|| 2/2 [00:36<00:00, 21.70s/it]\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RHEPS\n",
      "Base variable is  RH\n",
      "var is  TBPEPS\n",
      "Base variable is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQEPS\n",
      "Base variable is  PHQ\n",
      "var is  TPHYSTNDEPS\n",
      "Base variable is  TPHYSTND\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/136_POG_84G_RHTepsinput_30lev.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = load_pickle('./nn_config/scale_dicts/134_POG_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RHEPS','TBPEPS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQEPS','TPHYSTNDEPS','FSNT','FSNS','FLNT','FLNS']\n",
    "train_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/136_train_shuffle.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/134_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/136_valid.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/134_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 64), (1024, 64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = valid_gen[25]; X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2) Model without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1201 13:10:55.142812 23425363851072 deprecation.py:506] From /home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "for i in range (5):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "out = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel = tf.keras.models.Model(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 362,048\n",
      "Trainable params: 362,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG136.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13728/13728 [==============================] - 99s 7ms/step - loss: 351.9154 - val_loss: 317.7195\n",
      "Epoch 2/20\n",
      "13728/13728 [==============================] - 97s 7ms/step - loss: 303.0691 - val_loss: 304.3492\n",
      "Epoch 3/20\n",
      "13728/13728 [==============================] - 96s 7ms/step - loss: 294.5087 - val_loss: 298.8146\n",
      "Epoch 4/20\n",
      "13728/13728 [==============================] - 96s 7ms/step - loss: 290.1831 - val_loss: 296.5876\n",
      "Epoch 5/20\n",
      "13728/13728 [==============================] - 97s 7ms/step - loss: 287.4218 - val_loss: 293.9257\n",
      "Epoch 6/20\n",
      "13728/13728 [==============================] - 97s 7ms/step - loss: 285.4558 - val_loss: 292.1698\n",
      "Epoch 7/20\n",
      "13728/13728 [==============================] - 97s 7ms/step - loss: 283.8355 - val_loss: 291.8759\n",
      "Epoch 8/20\n",
      "13728/13728 [==============================] - 98s 7ms/step - loss: 282.3604 - val_loss: 292.4342\n",
      "Epoch 9/20\n",
      "13728/13728 [==============================] - 96s 7ms/step - loss: 281.2009 - val_loss: 290.4176\n",
      "Epoch 10/20\n",
      "13728/13728 [==============================] - 97s 7ms/step - loss: 280.1050 - val_loss: 290.1017\n",
      "Epoch 11/20\n",
      "13728/13728 [==============================] - 97s 7ms/step - loss: 279.1599 - val_loss: 286.5862\n",
      "Epoch 12/20\n",
      "13728/13728 [==============================] - 97s 7ms/step - loss: 278.3271 - val_loss: 286.1233\n",
      "Epoch 13/20\n",
      "13728/13728 [==============================] - 96s 7ms/step - loss: 277.5728 - val_loss: 290.6456\n",
      "Epoch 14/20\n",
      "13728/13728 [==============================] - 96s 7ms/step - loss: 276.8610 - val_loss: 285.1029\n",
      "Epoch 15/20\n",
      "13728/13728 [==============================] - 97s 7ms/step - loss: 276.2866 - val_loss: 284.6105\n",
      "Epoch 16/20\n",
      "13728/13728 [==============================] - 96s 7ms/step - loss: 275.7783 - val_loss: 288.3516\n",
      "Epoch 17/20\n",
      "13728/13728 [==============================] - 98s 7ms/step - loss: 275.2537 - val_loss: 285.5759\n",
      "Epoch 18/20\n",
      "13728/13728 [==============================] - 97s 7ms/step - loss: 274.8032 - val_loss: 285.6876\n",
      "Epoch 19/20\n",
      "13728/13728 [==============================] - 96s 7ms/step - loss: 274.3782 - val_loss: 283.5322\n",
      "Epoch 20/20\n",
      "13728/13728 [==============================] - 96s 7ms/step - loss: 274.0239 - val_loss: 283.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x154d954055c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3) Model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp2)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "for i in range (5):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "    densout = Dropout(rate=0.01)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "out2 = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel2 = tf.keras.models.Model(inp2,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 362,048\n",
      "Trainable params: 362,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG136_Dropout.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel2.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13728/13728 [==============================] - 110s 8ms/step - loss: 408.8735 - val_loss: 317.4173\n",
      "Epoch 2/20\n",
      "13728/13728 [==============================] - 108s 8ms/step - loss: 360.3003 - val_loss: 304.5859\n",
      "Epoch 3/20\n",
      "13728/13728 [==============================] - 108s 8ms/step - loss: 352.3446 - val_loss: 299.8754\n",
      "Epoch 4/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 348.0168 - val_loss: 296.7669\n",
      "Epoch 5/20\n",
      "13728/13728 [==============================] - 108s 8ms/step - loss: 345.3047 - val_loss: 296.6124\n",
      "Epoch 6/20\n",
      "13728/13728 [==============================] - 110s 8ms/step - loss: 343.6776 - val_loss: 297.5734\n",
      "Epoch 7/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 342.0906 - val_loss: 295.3697\n",
      "Epoch 8/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 340.8755 - val_loss: 294.3304\n",
      "Epoch 9/20\n",
      "13728/13728 [==============================] - 108s 8ms/step - loss: 340.0512 - val_loss: 295.4110\n",
      "Epoch 10/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 339.2587 - val_loss: 290.8541\n",
      "Epoch 11/20\n",
      "13728/13728 [==============================] - 110s 8ms/step - loss: 338.3407 - val_loss: 290.9425\n",
      "Epoch 12/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 337.6449 - val_loss: 290.6046\n",
      "Epoch 13/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 336.8456 - val_loss: 295.7491\n",
      "Epoch 14/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 336.3491 - val_loss: 290.7320\n",
      "Epoch 15/20\n",
      "13728/13728 [==============================] - 110s 8ms/step - loss: 335.6281 - val_loss: 291.7939\n",
      "Epoch 16/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 335.3146 - val_loss: 287.4943\n",
      "Epoch 17/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 334.8214 - val_loss: 290.7205\n",
      "Epoch 18/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 334.4441 - val_loss: 288.8455\n",
      "Epoch 19/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 334.0117 - val_loss: 288.4339\n",
      "Epoch 20/20\n",
      "13728/13728 [==============================] - 108s 8ms/step - loss: 333.7635 - val_loss: 287.3350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x154d88f48358>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel2.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1201 14:19:30.907169 23030937020224 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1201 14:19:30.907421 23030937020224 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RHEPS\n",
      "Base variable is  RH\n",
      "var is  TBPEPS\n",
      "Base variable is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQEPS\n",
      "Base variable is  PHQ\n",
      "var is  TPHYSTNDEPS\n",
      "Base variable is  TPHYSTND\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n",
      "100%|| 2/2 [00:36<00:00, 22.03s/it]\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RHEPS\n",
      "Base variable is  RH\n",
      "var is  TBPEPS\n",
      "Base variable is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQEPS\n",
      "Base variable is  PHQ\n",
      "var is  TPHYSTNDEPS\n",
      "Base variable is  TPHYSTND\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/137_POG_84G_p4K_RHTepsinput_30lev.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Train eps RH,(T-Ts) 30lev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1) Without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = load_pickle('./nn_config/scale_dicts/134_POG_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RHEPS','TfromTSEPS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQEPS','TPHYSTNDEPS','FSNT','FSNS','FLNT','FLNS']\n",
    "train_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/139_train_shuffle.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/138_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/139_valid.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/138_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 64), (1024, 64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = valid_gen[9]; X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "for i in range (5):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "out = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel = tf.keras.models.Model(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 362,048\n",
      "Trainable params: 362,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG139.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13728/13728 [==============================] - 162s 12ms/step - loss: 337.2676 - val_loss: 292.2296\n",
      "Epoch 2/20\n",
      "13728/13728 [==============================] - 160s 12ms/step - loss: 334.8176 - val_loss: 287.4976\n",
      "Epoch 3/20\n",
      "13728/13728 [==============================] - 159s 12ms/step - loss: 333.9356 - val_loss: 288.3272\n",
      "Epoch 4/20\n",
      "13728/13728 [==============================] - 156s 11ms/step - loss: 333.6413 - val_loss: 289.9234\n",
      "Epoch 5/20\n",
      "13728/13728 [==============================] - 159s 12ms/step - loss: 332.9615 - val_loss: 288.4107\n",
      "Epoch 6/20\n",
      "13728/13728 [==============================] - 159s 12ms/step - loss: 332.6279 - val_loss: 289.2598\n",
      "Epoch 7/20\n",
      "13728/13728 [==============================] - 160s 12ms/step - loss: 332.0529 - val_loss: 289.2730\n",
      "Epoch 8/20\n",
      "13728/13728 [==============================] - 161s 12ms/step - loss: 331.9261 - val_loss: 290.7738\n",
      "Epoch 9/20\n",
      "13728/13728 [==============================] - 163s 12ms/step - loss: 331.5786 - val_loss: 288.2428\n",
      "Epoch 10/20\n",
      "13728/13728 [==============================] - 173s 13ms/step - loss: 331.2518 - val_loss: 284.9100\n",
      "Epoch 11/20\n",
      "13728/13728 [==============================] - 203s 15ms/step - loss: 330.9283 - val_loss: 290.5274\n",
      "Epoch 12/20\n",
      "13728/13728 [==============================] - 185s 13ms/step - loss: 330.5675 - val_loss: 285.6857\n",
      "Epoch 13/20\n",
      "13728/13728 [==============================] - 184s 13ms/step - loss: 330.4638 - val_loss: 286.1920\n",
      "Epoch 14/20\n",
      "13728/13728 [==============================] - 175s 13ms/step - loss: 330.2924 - val_loss: 288.5566\n",
      "Epoch 15/20\n",
      "13728/13728 [==============================] - 163s 12ms/step - loss: 329.9763 - val_loss: 284.9788\n",
      "Epoch 16/20\n",
      "13728/13728 [==============================] - 162s 12ms/step - loss: 329.8220 - val_loss: 289.2089\n",
      "Epoch 17/20\n",
      "13728/13728 [==============================] - 158s 12ms/step - loss: 329.6656 - val_loss: 284.1199\n",
      "Epoch 18/20\n",
      "13728/13728 [==============================] - 161s 12ms/step - loss: 329.4196 - val_loss: 286.9564\n",
      "Epoch 19/20\n",
      "13728/13728 [==============================] - 162s 12ms/step - loss: 329.4065 - val_loss: 286.0969\n",
      "Epoch 20/20\n",
      "13728/13728 [==============================] - 161s 12ms/step - loss: 329.2296 - val_loss: 285.3449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x154d887e0b38>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel2.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2) With dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp2)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "for i in range (5):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "    densout = Dropout(rate=0.01)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "out2 = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel2 = tf.keras.models.Model(inp2,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 362,048\n",
      "Trainable params: 362,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG139_Dropout.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel2.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13728/13728 [==============================] - 167s 12ms/step - loss: 406.1932 - val_loss: 319.8354\n",
      "Epoch 2/20\n",
      "13728/13728 [==============================] - 161s 12ms/step - loss: 357.5996 - val_loss: 303.8901\n",
      "Epoch 3/20\n",
      "13728/13728 [==============================] - 164s 12ms/step - loss: 350.3048 - val_loss: 301.3602\n",
      "Epoch 4/20\n",
      "13728/13728 [==============================] - 165s 12ms/step - loss: 345.7416 - val_loss: 294.6618\n",
      "Epoch 5/20\n",
      "13728/13728 [==============================] - 162s 12ms/step - loss: 342.9153 - val_loss: 294.8703\n",
      "Epoch 6/20\n",
      "13728/13728 [==============================] - 162s 12ms/step - loss: 341.1751 - val_loss: 292.1221\n",
      "Epoch 7/20\n",
      "13728/13728 [==============================] - 161s 12ms/step - loss: 339.4255 - val_loss: 292.2285\n",
      "Epoch 8/20\n",
      "13728/13728 [==============================] - 162s 12ms/step - loss: 338.7682 - val_loss: 290.2843\n",
      "Epoch 9/20\n",
      "13728/13728 [==============================] - 163s 12ms/step - loss: 337.3511 - val_loss: 296.0719\n",
      "Epoch 10/20\n",
      "13728/13728 [==============================] - 159s 12ms/step - loss: 336.3831 - val_loss: 288.6354\n",
      "Epoch 11/20\n",
      "13728/13728 [==============================] - 162s 12ms/step - loss: 336.0567 - val_loss: 289.8444\n",
      "Epoch 12/20\n",
      "13728/13728 [==============================] - 160s 12ms/step - loss: 335.3889 - val_loss: 290.3740\n",
      "Epoch 13/20\n",
      "13728/13728 [==============================] - 160s 12ms/step - loss: 334.7095 - val_loss: 289.1541\n",
      "Epoch 14/20\n",
      "13728/13728 [==============================] - 159s 12ms/step - loss: 334.0413 - val_loss: 287.4955\n",
      "Epoch 15/20\n",
      "13728/13728 [==============================] - 160s 12ms/step - loss: 333.7087 - val_loss: 291.4298\n",
      "Epoch 16/20\n",
      "13728/13728 [==============================] - 160s 12ms/step - loss: 333.3742 - val_loss: 285.1579\n",
      "Epoch 17/20\n",
      "13728/13728 [==============================] - 161s 12ms/step - loss: 333.1332 - val_loss: 285.4227\n",
      "Epoch 18/20\n",
      "13728/13728 [==============================] - 161s 12ms/step - loss: 332.5685 - val_loss: 286.1223\n",
      "Epoch 19/20\n",
      "13728/13728 [==============================] - 162s 12ms/step - loss: 332.5254 - val_loss: 289.7487\n",
      "Epoch 20/20\n",
      "13728/13728 [==============================] - 162s 12ms/step - loss: 332.3722 - val_loss: 286.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x154d8839bac8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel2.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Train p RH,T to dRH/dt, dT/dt 30 lev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1) Without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = {\n",
    "    'dRHdt': 0.01*L_V/G, # Arbitrary 0.1 factor as specific humidity is generally below 2%  \n",
    "    'TPHYSTND': C_P/G, \n",
    "    'FSNT': 1, \n",
    "    'FSNS': 1, \n",
    "    'FLNT': 1, \n",
    "    'FLNS': 1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes representative value for PS since purpose is normalization\n",
    "PS = 1e5; P0 = 1e5;\n",
    "P = P0*hyai+PS*hybi; # Total pressure [Pa]\n",
    "dP = P[1:]-P[:-1]; # Differential pressure [Pa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['dRHdt','TPHYSTND']:\n",
    "    scale_dict[v] *= dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce humidity tendencies above level 10\n",
    "scale_dict['dRHdt'][:11] *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle('./nn_config/scale_dicts/142_POG_scaling.pkl', scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/142_POG_84G_RHinput_dRHoutput.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RH','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['dRHdt','TPHYSTND','FSNT','FSNS','FLNT','FLNS']\n",
    "train_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/142_train_shuffle.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/141_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/142_valid.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/141_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 64), (1024, 64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = valid_gen[19]; X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1202 10:23:04.582470 22842140297024 deprecation.py:506] From /home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "for i in range (5):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "out = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel = tf.keras.models.Model(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 362,048\n",
      "Trainable params: 362,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG142_Dropout.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13728/13728 [==============================] - 103s 8ms/step - loss: 3907.3301 - val_loss: 3477.9009\n",
      "Epoch 2/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3455.0785 - val_loss: 3347.8832\n",
      "Epoch 3/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3352.1922 - val_loss: 3284.8219\n",
      "Epoch 4/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3291.3112 - val_loss: 3256.3507\n",
      "Epoch 5/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3251.5975 - val_loss: 3211.0658\n",
      "Epoch 6/20\n",
      "13728/13728 [==============================] - 103s 7ms/step - loss: 3223.8883 - val_loss: 3197.5396\n",
      "Epoch 7/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3202.2690 - val_loss: 3186.6846\n",
      "Epoch 8/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3185.2506 - val_loss: 3186.9775\n",
      "Epoch 9/20\n",
      "13728/13728 [==============================] - 103s 7ms/step - loss: 3169.9252 - val_loss: 3177.1868\n",
      "Epoch 10/20\n",
      "13728/13728 [==============================] - 103s 7ms/step - loss: 3157.5644 - val_loss: 3175.4003\n",
      "Epoch 11/20\n",
      "13728/13728 [==============================] - 101s 7ms/step - loss: 3146.5437 - val_loss: 3167.8170\n",
      "Epoch 12/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3136.6168 - val_loss: 3158.5464\n",
      "Epoch 13/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3128.2925 - val_loss: 3159.0193\n",
      "Epoch 14/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3120.6793 - val_loss: 3153.0429\n",
      "Epoch 15/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3112.7230 - val_loss: 3126.1663\n",
      "Epoch 16/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3105.1550 - val_loss: 3143.0138\n",
      "Epoch 17/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3100.3817 - val_loss: 3163.3505\n",
      "Epoch 18/20\n",
      "13728/13728 [==============================] - 102s 7ms/step - loss: 3093.9211 - val_loss: 3116.6461\n",
      "Epoch 19/20\n",
      "13728/13728 [==============================] - 103s 7ms/step - loss: 3088.6187 - val_loss: 3135.3015\n",
      "Epoch 20/20\n",
      "13728/13728 [==============================] - 103s 7ms/step - loss: 3083.3036 - val_loss: 3114.6903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14c5c0ab7710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1202 19:12:07.274036 23284832073536 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1202 19:12:07.274271 23284832073536 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/143_POG_84G_p4K_RHinput_dRHoutput.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2) With dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = load_pickle('./nn_config/scale_dicts/142_POG_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp3 = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp3)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "for i in range (5):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "    densout = Dropout(rate=0.01)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "out3 = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel3 = tf.keras.models.Model(inp3,out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG142_DropoutYES.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel3.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nep = 20\n",
    "NNmodel3.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Train eps RH,T-Ts to dRH/dt, dT/dt 30 lev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1) Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1202 19:06:47.084547 23209503491904 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1202 19:06:47.084784 23209503491904 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E1202 19:11:59.294061 22754576410432 ultratb.py:155] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/IPython/utils/_process_posix.py\", line 161, in system\n",
      "    res_idx = child.expect_list(patterns, self.read_timeout)\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/pexpect/spawnbase.py\", line 369, in expect_list\n",
      "    return exp.expect_loop(timeout)\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/pexpect/expect.py\", line 111, in expect_loop\n",
      "    incoming = spawn.read_nonblocking(spawn.maxread, timeout)\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/pexpect/pty_spawn.py\", line 499, in read_nonblocking\n",
      "    if (timeout != 0) and select(timeout):\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/pexpect/pty_spawn.py\", line 449, in select\n",
      "    return select_ignore_interrupts([self.child_fd], [], [], timeout)[0]\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/pexpect/utils.py\", line 143, in select_ignore_interrupts\n",
      "    return select.select(iwtd, owtd, ewtd, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-eea5651291ae>\", line 1, in <module>\n",
      "    get_ipython().system('python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/146_POG_84G_p4K_RHTfromTSepsinput_dRHdtoutput_30lev.yml')\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2453, in system_piped\n",
      "    self.user_ns['_exit_code'] = system(self.var_expand(cmd, depth=1))\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/IPython/utils/_process_posix.py\", line 185, in system\n",
      "    child.terminate(force=True)\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/pexpect/pty_spawn.py\", line 641, in terminate\n",
      "    time.sleep(self.delayafterterminate)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/t/Tom.Beucler/miniconda3/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;31m# know whether we've finished (if we matched EOF) or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0mres_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# Still have time left, so read more data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mread_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# (possibly timeout=None), we call select() with a timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mselect_ignore_interrupts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild_fd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pexpect/utils.py\u001b[0m in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miwtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3326\u001b[0;31m                     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3327\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/api/_v1/keras/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/146_POG_84G_p4K_RHTfromTSepsinput_dRHdtoutput_30lev.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2452\u001b[0m         \u001b[0;31m# Instead, we store the exit_code in user_ns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2453\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# Ensure the subprocess really is terminated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;31m# add isalive check, to ensure exitstatus is set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGHUP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterterminate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2039\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3341\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3342\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3344\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3345\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2041\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2043\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1385\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1288\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m             )\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0mformatted_exceptions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m             \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/146_POG_84G_p4K_RHTfromTSepsinput_dRHdtoutput_30lev.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/145_POG_84G_RHTfromTSepsinput_dRHdtoutput_30lev.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = {\n",
    "    'dRHdtEPS': 0.01*L_V/G,  \n",
    "    'TPHYSTNDEPS': C_P/G, \n",
    "    'FSNT': 1, \n",
    "    'FSNS': 1, \n",
    "    'FLNT': 1, \n",
    "    'FLNS': 1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS = 1e5\n",
    "eps_res = 30\n",
    "dP = PS/eps_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in ['dRHdtEPS','TPHYSTNDEPS']:\n",
    "    scale_dict[v] *= dP*np.ones((30,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce humidity tendencies above level 20\n",
    "scale_dict['dRHdtEPS'][20:] *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle('./nn_config/scale_dicts/144_POG_scaling.pkl', scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RHEPS','TfromTSEPS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['dRHdtEPS','TPHYSTNDEPS','FSNT','FSNS','FLNT','FLNS']\n",
    "train_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/145_train_shuffle.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/144_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/145_valid.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/144_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 64), (1024, 64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = valid_gen[12]; X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2) Without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1202 17:45:12.020156 22985903331136 deprecation.py:506] From /home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "inp2 = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp2)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "for i in range (5):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "out2 = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel2 = tf.keras.models.Model(inp2,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 362,048\n",
      "Trainable params: 362,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG144.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel2.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13728/13728 [==============================] - 96s 7ms/step - loss: 1664.8475 - val_loss: 1482.9146\n",
      "Epoch 2/20\n",
      "13728/13728 [==============================] - 95s 7ms/step - loss: 1467.2349 - val_loss: 1428.6084\n",
      "Epoch 3/20\n",
      "13728/13728 [==============================] - 95s 7ms/step - loss: 1427.2517 - val_loss: 1408.4057\n",
      "Epoch 4/20\n",
      "13728/13728 [==============================] - 95s 7ms/step - loss: 1405.3470 - val_loss: 1395.8530\n",
      "Epoch 5/20\n",
      "13728/13728 [==============================] - 95s 7ms/step - loss: 1390.5816 - val_loss: 1385.9915\n",
      "Epoch 6/20\n",
      "13728/13728 [==============================] - 95s 7ms/step - loss: 1380.1575 - val_loss: 1384.6017\n",
      "Epoch 7/20\n",
      "13728/13728 [==============================] - 95s 7ms/step - loss: 1371.1753 - val_loss: 1359.9962\n",
      "Epoch 8/20\n",
      "13728/13728 [==============================] - 95s 7ms/step - loss: 1364.1803 - val_loss: 1358.0853\n",
      "Epoch 9/20\n",
      "13728/13728 [==============================] - 94s 7ms/step - loss: 1358.2819 - val_loss: 1358.0718\n",
      "Epoch 10/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1352.9366 - val_loss: 1348.3508\n",
      "Epoch 11/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1348.4757 - val_loss: 1351.4251\n",
      "Epoch 12/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1344.3508 - val_loss: 1345.7252\n",
      "Epoch 13/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1340.6171 - val_loss: 1361.8419\n",
      "Epoch 14/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1337.3086 - val_loss: 1349.3764\n",
      "Epoch 15/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1334.2479 - val_loss: 1343.9668\n",
      "Epoch 16/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1331.7396 - val_loss: 1345.9574\n",
      "Epoch 17/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1328.8022 - val_loss: 1340.1380\n",
      "Epoch 18/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1326.5380 - val_loss: 1342.4844\n",
      "Epoch 19/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1324.3370 - val_loss: 1350.1259\n",
      "Epoch 20/20\n",
      "13728/13728 [==============================] - 92s 7ms/step - loss: 1322.2843 - val_loss: 1346.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e7313bb940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel2.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Train p RH,T to PHQflux and TPHYSTNDflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1205 09:17:01.453843 22640739206976 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1205 09:17:01.454074 22640739206976 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RH\n",
      "var is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUX\n",
      "var is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: []\n",
      "100%|| 1/1 [00:07<00:00,  7.65s/it]\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RH\n",
      "var is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUX\n",
      "var is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: []\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/147_POG_RHinput_FLUXoutput_test.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1205 09:21:10.943515 23364358723392 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1205 09:21:10.943761 23364358723392 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RH\n",
      "var is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUX\n",
      "var is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n",
      "100%|| 2/2 [00:35<00:00, 21.19s/it]\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RH\n",
      "var is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUX\n",
      "var is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/148_POG_84G_RHinput_FLUXoutput.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = {\n",
    "    'PHQFLUX': 100,  \n",
    "    'TPHYSTNDFLUX': 100, \n",
    "    'FSNT': 1, \n",
    "    'FSNS': 1, \n",
    "    'FLNT': 1, \n",
    "    'FLNS': 1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle('./nn_config/scale_dicts/148_POG_scaling.pkl', scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RH','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQFLUX','TPHYSTNDFLUX','FSNT','FSNS','FLNT','FLNS']\n",
    "train_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/148_train_shuffle.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/147_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/148_valid.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/147_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 64), (1024, 64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = valid_gen[12]; X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 09:35:59.459128 22712538859328 deprecation.py:506] From /home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "inp2 = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp2)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "for i in range (5):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "    densout = Dropout(rate=0.01)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "out2 = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel2 = tf.keras.models.Model(inp2,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 362,048\n",
      "Trainable params: 362,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG148.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel2.compile(tf.keras.optimizers.RMSprop(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 667.1096 - val_loss: 561.5792\n",
      "Epoch 2/20\n",
      "13728/13728 [==============================] - 105s 8ms/step - loss: 578.5642 - val_loss: 543.7322\n",
      "Epoch 3/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 561.5372 - val_loss: 481.6702\n",
      "Epoch 4/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 551.7746 - val_loss: 506.9128\n",
      "Epoch 5/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 546.0016 - val_loss: 476.5985\n",
      "Epoch 6/20\n",
      "13728/13728 [==============================] - 105s 8ms/step - loss: 541.3156 - val_loss: 480.7034\n",
      "Epoch 7/20\n",
      "13728/13728 [==============================] - 105s 8ms/step - loss: 538.3044 - val_loss: 499.2775\n",
      "Epoch 8/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 535.8211 - val_loss: 473.8935\n",
      "Epoch 9/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 533.1369 - val_loss: 461.8422\n",
      "Epoch 10/20\n",
      "13728/13728 [==============================] - 105s 8ms/step - loss: 530.8585 - val_loss: 473.0623\n",
      "Epoch 11/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 529.4743 - val_loss: 462.6219\n",
      "Epoch 12/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 528.4751 - val_loss: 467.4911\n",
      "Epoch 13/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 527.1916 - val_loss: 459.1762\n",
      "Epoch 14/20\n",
      "13728/13728 [==============================] - 105s 8ms/step - loss: 525.9513 - val_loss: 477.8085\n",
      "Epoch 15/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 524.9014 - val_loss: 462.4696\n",
      "Epoch 16/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 523.6776 - val_loss: 476.3888\n",
      "Epoch 17/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 523.1033 - val_loss: 461.2057\n",
      "Epoch 18/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 522.2307 - val_loss: 460.2994\n",
      "Epoch 19/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 521.1866 - val_loss: 465.0652\n",
      "Epoch 20/20\n",
      "13728/13728 [==============================] - 105s 8ms/step - loss: 520.2939 - val_loss: 455.2112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a79d740438>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel2.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1205 10:11:19.440927 22603803506496 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1205 10:11:19.441174 22603803506496 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RH\n",
      "var is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUX\n",
      "var is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n",
      "100%|| 2/2 [00:35<00:00, 21.10s/it]\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RH\n",
      "var is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUX\n",
      "var is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/149_POG_84G_p4K_RHinput_FLUXoutput.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11) Train eps RH,T to PHQflux and TPHYSTNDflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1205 10:26:53.769256 23334440982336 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1205 10:26:53.769515 23334440982336 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RHEPS\n",
      "Base variable is  RH\n",
      "var is  TBPEPS\n",
      "Base variable is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUXEPS\n",
      "Base variable is  PHQFLUX\n",
      "var is  TPHYSTNDFLUXEPS\n",
      "Base variable is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n",
      "100%|| 2/2 [00:37<00:00, 22.66s/it]\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RHEPS\n",
      "Base variable is  RH\n",
      "var is  TBPEPS\n",
      "Base variable is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUXEPS\n",
      "Base variable is  PHQFLUX\n",
      "var is  TPHYSTNDFLUXEPS\n",
      "Base variable is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/151_POG_84G_RHinput_FLUXoutput_EPS.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1205 12:59:50.966123 23271771236160 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1205 12:59:50.966383 23271771236160 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RHEPS\n",
      "Base variable is  RH\n",
      "var is  TBPEPS\n",
      "Base variable is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUXEPS\n",
      "Base variable is  PHQFLUX\n",
      "var is  TPHYSTNDFLUXEPS\n",
      "Base variable is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: []\n",
      "100%|| 1/1 [00:07<00:00,  7.99s/it]\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RHEPS\n",
      "Base variable is  RH\n",
      "var is  TBPEPS\n",
      "Base variable is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUXEPS\n",
      "Base variable is  PHQFLUX\n",
      "var is  TPHYSTNDFLUXEPS\n",
      "Base variable is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: []\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/150_POG_RHinput_FLUXoutput_EPStest.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = {\n",
    "    'PHQFLUXEPS': 100,  \n",
    "    'TPHYSTNDFLUXEPS': 100, \n",
    "    'FSNT': 1, \n",
    "    'FSNS': 1, \n",
    "    'FLNT': 1, \n",
    "    'FLNS': 1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle('./nn_config/scale_dicts/151_POG_scaling.pkl', scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RHEPS','TBPEPS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQFLUXEPS','TPHYSTNDFLUXEPS','FSNT','FSNS','FLNT','FLNS']\n",
    "train_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/151_train_shuffle.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/150_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = '/local/Tom.Beucler/SPCAM_PHYS/151_valid.nc',\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = '/local/Tom.Beucler/SPCAM_PHYS/150_norm.nc',\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 64), (1024, 64))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = valid_gen[5]; X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(64,))\n",
    "densout = Dense(256, activation='linear')(inp)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "for i in range (5):\n",
    "    densout = Dense(256, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "    densout = Dropout(rate=0.01)(densout)\n",
    "densout = Dense(64, activation='linear')(densout)\n",
    "densout = Dropout(rate=0.01)(densout)\n",
    "out = LeakyReLU(alpha=0.3)(densout)\n",
    "NNmodel = tf.keras.models.Model(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 362,048\n",
      "Trainable params: 362,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/POG151.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNmodel.compile(tf.keras.optimizers.Adam(),loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 565.1663 - val_loss: 429.7754\n",
      "Epoch 2/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 493.7473 - val_loss: 422.5396\n",
      "Epoch 3/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 479.9125 - val_loss: 408.0037\n",
      "Epoch 4/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 473.1182 - val_loss: 399.2956\n",
      "Epoch 5/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 468.0725 - val_loss: 397.7123\n",
      "Epoch 6/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 464.7278 - val_loss: 394.3068\n",
      "Epoch 7/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 461.8383 - val_loss: 390.1633\n",
      "Epoch 8/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 460.0748 - val_loss: 391.1540\n",
      "Epoch 9/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 457.8499 - val_loss: 386.3749\n",
      "Epoch 10/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 456.4389 - val_loss: 385.8528\n",
      "Epoch 11/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 455.5230 - val_loss: 387.5217\n",
      "Epoch 12/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 454.1723 - val_loss: 388.4896\n",
      "Epoch 13/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 453.1371 - val_loss: 387.6448\n",
      "Epoch 14/20\n",
      "13728/13728 [==============================] - 111s 8ms/step - loss: 451.8387 - val_loss: 381.9556\n",
      "Epoch 15/20\n",
      "13728/13728 [==============================] - 109s 8ms/step - loss: 451.4569 - val_loss: 381.9776\n",
      "Epoch 16/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 450.6321 - val_loss: 381.0727\n",
      "Epoch 17/20\n",
      "13728/13728 [==============================] - 107s 8ms/step - loss: 449.6988 - val_loss: 381.5731\n",
      "Epoch 18/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 449.3150 - val_loss: 390.2929\n",
      "Epoch 19/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 448.6278 - val_loss: 383.9973\n",
      "Epoch 20/20\n",
      "13728/13728 [==============================] - 106s 8ms/step - loss: 448.3834 - val_loss: 386.8006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a79d76e6d8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nep = 20\n",
    "NNmodel.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,callbacks=[earlyStopping,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1205 14:15:35.690033 22523727669056 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W1205 14:15:35.690269 22523727669056 deprecation_wrapper.py:119] From /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RHEPS\n",
      "Base variable is  RH\n",
      "var is  TBPEPS\n",
      "Base variable is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUXEPS\n",
      "Base variable is  PHQFLUX\n",
      "var is  TPHYSTNDFLUXEPS\n",
      "Base variable is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n",
      "100%|| 2/2 [00:37<00:00, 22.55s/it]\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: In xarray version 0.13 `auto_combine` will be deprecated.\n",
      "  coords=coords)\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/xarray/backends/api.py:783: FutureWarning: Also `open_mfdataset` will no longer accept a `concat_dim` argument.\n",
      "To get equivalent behaviour from now on please use the new\n",
      "`combine_nested` function instead (or the `combine='nested'` option to\n",
      "`open_mfdataset`).The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset` to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in in future, please use the\n",
      "new `combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  coords=coords)\n",
      "var is  RHEPS\n",
      "Base variable is  RH\n",
      "var is  TBPEPS\n",
      "Base variable is  TBP\n",
      "var is  PS\n",
      "var is  SOLIN\n",
      "var is  SHFLX\n",
      "var is  LHFLX\n",
      "var is  PHQFLUXEPS\n",
      "Base variable is  PHQFLUX\n",
      "var is  TPHYSTNDFLUXEPS\n",
      "Base variable is  TPHYSTNDFLUX\n",
      "var is  FSNT\n",
      "var is  FSNS\n",
      "var is  FLNT\n",
      "var is  FLNS\n",
      "These time steps are cut: [ 143  287  431  575  719  863 1007 1151 1295 1439 1583]\n"
     ]
    }
   ],
   "source": [
    "!python preprocessing-11132019.py -c /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/pp_config/152_POG_84G_p4K_RHinput_FLUXoutput_EPS.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
